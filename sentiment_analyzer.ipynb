{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kerK4HIvgmbN"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "KO4h8BognG6f"
   },
   "outputs": [],
   "source": [
    "reviews=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cFcD47WOnG9X"
   },
   "outputs": [],
   "source": [
    "with open('sentiment.txt','r') as f:\n",
    "     reviews=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oyx2M8vgnHAV"
   },
   "outputs": [],
   "source": [
    " data=pd.DataFrame([rv.split('\\t') for rv in reviews.split('\\n')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1kZFG4eHnHDv"
   },
   "outputs": [],
   "source": [
    "data.columns=['reviews','sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "AlmQypFcXTKR",
    "outputId": "1f7ef04f-fb2b-4a17-e866-d5bee1a5b4b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews sentiment\n",
       "0  A very, very, very slow-moving, aimless movie ...         0\n",
       "1  Not sure who was more lost - the flat characte...         0\n",
       "2  Attempting artiness with black & white and cle...         0\n",
       "3       Very little music or anything to speak of.           0\n",
       "4  The best scene in the movie was when Gerardo i...         1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "dyp5iiu6Xnau"
   },
   "outputs": [],
   "source": [
    "class vocobalary_builder:\n",
    "      word_to_index={}\n",
    "      index_to_word={}\n",
    "      counter=0\n",
    "      max_len=0\n",
    "\n",
    "      def add_token(self,token):\n",
    "          if token not in self.word_to_index:\n",
    "             self.word_to_index[token]=self.counter\n",
    "             self.index_to_word[self.counter]=token\n",
    "             self.counter+=1\n",
    "\n",
    "      def add_tokens(self,review):\n",
    "          review=review.lower()\n",
    "          split=review.split()\n",
    "          if len(split)>self.max_len:\n",
    "              self.max_len=len(split)\n",
    "          for token in review.split():\n",
    "              self.add_token(token)\n",
    "\n",
    "      def get_index_of_token(self,token):\n",
    "          return self.word_to_index.get(token)\n",
    "\n",
    "      def get_token_of_index(self,index):\n",
    "          return self.index_to_word.get(index)\n",
    "\n",
    "      def get_pedded_review(self,review):\n",
    "          review=review.lower()\n",
    "          split=review.split()\n",
    "          #print(split)\n",
    "          return [self.word_to_index.get(token) for token in split] + [0]*(self.max_len-len(split))\n",
    "\n",
    "          # do backward padding\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "oION4qCqipa_"
   },
   "outputs": [],
   "source": [
    "vb=vocobalary_builder()\n",
    "encoded_sentences=[]\n",
    "for index, row in data.iterrows():\n",
    "    vb.add_tokens(row['reviews'])\n",
    "\n",
    "\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    encode_sent=vb.get_pedded_review(row['reviews'])\n",
    "    encoded_sentences.append(encode_sent)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DS6F-hONjFvU",
    "outputId": "8c2c67fe-2622-418a-d6cb-ad1b7c3009dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vb.get_index_of_token('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "WdbN3xOBsZdS"
   },
   "outputs": [],
   "source": [
    "batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-NaIN9RQsion",
    "outputId": "f56bb36b-162d-491a-eae3-dd62fe5e34bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 5, 14, 91, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(vb.get_pedded_review('the movie was good'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "YE-y5mPmvh1R"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "model design\n",
    "i will keep first layer as embedding layer\n",
    "second layer will be lstm layer\n",
    "third layer will be sigmoid layer\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "class sentiment_analyzer(nn.Module):\n",
    "      def __init__(self,vocab_dim,embedding_dim,n_hidden,n_output,no_of_layers,drop_p=0.8):\n",
    "          super().__init__()\n",
    "          self.vocab_dim=vocab_dim\n",
    "          self.embedding_dim=embedding_dim\n",
    "          self.no_of_layers=no_of_layers\n",
    "          self.n_hidden=n_hidden\n",
    "          self.n_output=n_output\n",
    "          self.embedding=nn.Embedding(vocab_dim,embedding_dim)\n",
    "          self.lstm=nn.LSTM(embedding_dim,n_hidden,no_of_layers,batch_first=True,dropout=0.8)\n",
    "          self.dropout=nn.Dropout(drop_p)\n",
    "          self.fc = nn.Linear(n_hidden, n_output)\n",
    "\n",
    "          self.sigmoid=nn.Sigmoid()\n",
    "\n",
    "\n",
    "      def forward(self,input_words):\n",
    "          # all input words become part of our embedding layer during training\n",
    "          embedded_words=self.embedding(input_words)\n",
    "          lstm_out,h=self.lstm(embedded_words)\n",
    "          lstm_out =self.dropout(lstm_out)\n",
    "          lstm_out = lstm_out.contiguous().view(-1,self.n_hidden)\n",
    "          fc_out=self.fc(lstm_out)\n",
    "          sigmoid_out=self.sigmoid(fc_out)\n",
    "          sigmoid_out = sigmoid_out.view(batch_size, -1)\n",
    "          sigmoid_last=sigmoid_out[:, -1]\n",
    "          return sigmoid_last,h\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "tZ3LSx3IJLpJ"
   },
   "outputs": [],
   "source": [
    "#convert encoded_sentences to numpy array\n",
    "encoded_sentences=np.array(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "jxhJ42gzxMDn"
   },
   "outputs": [],
   "source": [
    "vocab_len=len(vb.word_to_index)\n",
    "embedding_dim=80\n",
    "n_hidden=2\n",
    "n_output=1\n",
    "no_of_layers=2\n",
    "model=sentiment_analyzer(vocab_len,embedding_dim,n_hidden,n_output,no_of_layers)\n",
    "#optimizer=optim.Adam(model.parameters(),lr=0.001)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_fun=nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "20zME5fdNTb2"
   },
   "outputs": [],
   "source": [
    "labels = np.array([int(x) for x in data['sentiment'].values])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "UEtqjxcs5od2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "OnWxuzWQjZHy"
   },
   "outputs": [],
   "source": [
    "#now lets split train test and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x,test_x,train_y,test_y=train_test_split(encoded_sentences,labels,test_size=0.20)\n",
    "test_x,val_x,test_y,val_y=train_test_split(encoded_sentences,labels,test_size=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "dUzBFjwvqpX5"
   },
   "outputs": [],
   "source": [
    "train_x = torch.Tensor(train_x).long()\n",
    "valid_x = torch.Tensor(val_x).long()\n",
    "test_x = torch.Tensor(test_x).long()\n",
    "\n",
    "train_y = torch.Tensor(train_y)\n",
    "valid_y = torch.Tensor(val_y)\n",
    "test_y = torch.Tensor(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "8IZyVbzZjZLM"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "QF9Coa-_KFiL"
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_x, train_y)\n",
    "valid_data = TensorDataset(valid_x, valid_y)\n",
    "test_data = TensorDataset(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "1TWH-4-dop7V"
   },
   "outputs": [],
   "source": [
    "#now we will create tensor dataset and decleare batch size =1\n",
    "batch_siz=1\n",
    "train_loader=DataLoader(train_data,batch_size=batch_siz,shuffle=True)\n",
    "valid_loader=DataLoader(valid_data,batch_size=batch_siz,shuffle=True)\n",
    "test_loader=DataLoader(test_data,batch_size=batch_siz,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "Jo3yl52DD4yP"
   },
   "outputs": [],
   "source": [
    "print_every=500\n",
    "step=0\n",
    "n_epochs=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AjP6KlLxJML_",
    "outputId": "350b9c5f-54b4-4cb9-87f4-dfb84cd2e64b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-55-004f00678d9a>:10: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3 Step: 500 Training Loss: 0.7624 Validation Loss: 0.7056\n",
      "Epoch: 1/3 Step: 1000 Training Loss: 0.4867 Validation Loss: 0.7009\n",
      "Epoch: 1/3 Step: 1500 Training Loss: 0.5161 Validation Loss: 0.6964\n",
      "Epoch: 1/3 Step: 2000 Training Loss: 0.5281 Validation Loss: 0.6961\n",
      "Epoch: 2/3 Step: 2500 Training Loss: 0.5178 Validation Loss: 0.6960\n",
      "Epoch: 2/3 Step: 3000 Training Loss: 0.6635 Validation Loss: 0.6943\n",
      "Epoch: 2/3 Step: 3500 Training Loss: 0.5808 Validation Loss: 0.6938\n",
      "Epoch: 2/3 Step: 4000 Training Loss: 0.5824 Validation Loss: 0.6939\n",
      "Epoch: 2/3 Step: 4500 Training Loss: 0.8052 Validation Loss: 0.6932\n",
      "Epoch: 3/3 Step: 5000 Training Loss: 0.8064 Validation Loss: 0.6934\n",
      "Epoch: 3/3 Step: 5500 Training Loss: 0.7116 Validation Loss: 0.6933\n",
      "Epoch: 3/3 Step: 6000 Training Loss: 0.6058 Validation Loss: 0.6934\n",
      "Epoch: 3/3 Step: 6500 Training Loss: 0.7774 Validation Loss: 0.6934\n",
      "Epoch: 3/3 Step: 7000 Training Loss: 0.6343 Validation Loss: 0.6930\n"
     ]
    }
   ],
   "source": [
    "#now we will iterate trainLoader to train model\n",
    "\n",
    "for epoch in range(3):\n",
    "    for inputs,labels in train_loader:\n",
    "        step+=1\n",
    "        model.zero_grad()\n",
    "        pred_label,h=model(inputs)\n",
    "        loss=loss_fun(pred_label,labels.float())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "        #print(loss)\n",
    "        if (step % print_every) == 0:\n",
    "            model.eval()\n",
    "            valid_losses = []\n",
    "            for v_inputs, v_labels in valid_loader:\n",
    "\n",
    "                v_output, v_h = model(v_inputs)\n",
    "                v_loss = loss_fun(v_output, v_labels.float())\n",
    "                valid_losses.append(v_loss.item())\n",
    "            print(\"Epoch: {}/{}\".format((epoch+1), n_epochs),\n",
    "                  \"Step: {}\".format(step),\n",
    "                  \"Training Loss: {:.4f}\".format(loss.item()),\n",
    "                  \"Validation Loss: {:.4f}\".format(np. mean(valid_losses)))\n",
    "            model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "BesSZSUd2Bpd"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'lstm_sentiment_analyzer.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SI6ssTecOsy5",
    "outputId": "e71eade7-96a9-422a-c7bf-edacf595784c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6933\n",
      "Test Accuracy: 0.49\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_losses=[]\n",
    "num_correct=0\n",
    "for inputs,label in test_loader:\n",
    "    output,h=model(inputs)\n",
    "    loss=loss_fun(output,label.float())\n",
    "    #print(output)\n",
    "    preds = torch.round(output.squeeze())\n",
    "    test_losses.append(loss.item())\n",
    "    correct_tensor = preds.eq(label.float().view_as(preds))\n",
    "    correct = np.squeeze(correct_tensor.numpy())\n",
    "    #print('correct value',correct)\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "\n",
    "print(\"Test Loss: {:.4f}\".format(np.mean(test_losses)))\n",
    "print(\"Test Accuracy: {:.2f}\".format(num_correct/len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "NlqjXVKkSD5P"
   },
   "outputs": [],
   "source": [
    "def predict_review(review):\n",
    "    model.eval()\n",
    "    review=vb.get_pedded_review(review)\n",
    "    review_tensor=torch.tensor(review)\n",
    "    output,h=model(review_tensor)\n",
    "    print(output)\n",
    "    msg = \"This is a positive review.\" if output >= 0.5 else           \"This is a negative review.\"\n",
    "    print(msg)\n",
    "    print('Prediction = ' + str(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1h60j5u5Yuux",
    "outputId": "989aed63-9476-4a9a-cd11-e49bb2a8b324"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4960], grad_fn=<SelectBackward0>)\n",
      "This is a negative review.\n",
      "Prediction = tensor([0.4960], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "predict_review('worst movie')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "xA4ew_N_Y0oF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
